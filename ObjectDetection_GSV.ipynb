{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This is a script for deploying the pre-trained Object Detection model to detect communal water points in your downloaded dataset of Google Street View imagery. You will need the folllowing:\n",
        "\n",
        "*  Roboflow API key: ([Tutorial](https://docs.roboflow.com/api-reference/authentication))\n",
        "* Downloaded Google Street View images with metadata file from desired geographic area ([Tutorial](https://github.com/neildpatel/waterpointCNN/blob/main/ImageDownload_GSV.ipynb))\n",
        "\n",
        "This script was partially adapted from a tutorial developed by researchers at MIT's Senseable City Lab (Director: Professor Carlo Ratti) for the 11.320 Digital City Design Lab course in Spring 2023. See https://senseable.mit.edu/ to learn more about the lab's work. Special gratitude to Prof. Carlo Ratti, [Claire Gorman](https://www.linkedin.com/in/claire-gorman-5465b7167/), [Rohit Sanatani](https://www.linkedin.com/in/rohit-priyadarshi-sanatani-14311595/), and [Nikita Klimenko](https://www.linkedin.com/in/nikita-klimenko/) for their support in developing this project."
      ],
      "metadata": {
        "id": "6VEbfem6Vc9Z"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4XGxDrCkeip"
      },
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gmkla0TMFMw"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cPY9Ou4sWs_"
      },
      "outputs": [],
      "source": [
        "#@title Imports and function definitions\n",
        "\n",
        "# For running inference on the TF-Hub module.\n",
        "import tensorflow as tf\n",
        "import tarfile\n",
        "import os\n",
        "from os import listdir\n",
        "import json\n",
        "\n",
        "# For running inference using Roboflow\n",
        "!pip install roboflow\n",
        "from roboflow import Roboflow\n",
        "\n",
        "# For downloading the image.\n",
        "import matplotlib.pyplot as plt\n",
        "import tempfile\n",
        "from six.moves.urllib.request import urlopen\n",
        "from six import BytesIO\n",
        "\n",
        "# For drawing onto the image.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from PIL import ImageColor\n",
        "from PIL import ImageDraw\n",
        "from PIL import ImageFont\n",
        "from PIL import ImageOps\n",
        "\n",
        "# For measuring the inference time.\n",
        "import time\n",
        "\n",
        "# For data visualization\n",
        "import geopandas\n",
        "import folium\n",
        "import io\n",
        "import branca.colormap as cm\n",
        "\n",
        "# Print Tensorflow version\n",
        "print(tf.__version__)\n",
        "\n",
        "# Check available GPU devices.\n",
        "print(\"The following GPU devices are available: %s\" % tf.test.gpu_device_name())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1Za80HF6KHW"
      },
      "outputs": [],
      "source": [
        "# Load object detection model from Roboflow\n",
        "rf = Roboflow(api_key='xxx') # Replace 'xxx' with your Roboflow API key\n",
        "project = rf.workspace(\"neil-patel\").project(\"lagos-water-point-detections\")\n",
        "dataset = project.version(3).download(\"yolov5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIpPaa7x28kJ"
      },
      "outputs": [],
      "source": [
        "import os, sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKqhsxmi3IVJ"
      },
      "outputs": [],
      "source": [
        "# Set a path to the Google Drive folder with your downloaded Google Street View images\n",
        "YOUR_PATH = 'xxx'\n",
        "os.chdir(YOUR_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D19UCu9Q2-_8"
      },
      "source": [
        "## Apply module"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZn4oYVt4xUr"
      },
      "source": [
        "RUN ON DOWNLOADED STREET VIEW DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNZ3bECg2xps"
      },
      "outputs": [],
      "source": [
        "#Load Data\n",
        "savename = 'detections.json'\n",
        "image_directory = YOUR_PATH\n",
        "data_file = \"filepath\" # Change 'filepath' to the file path for the metadata.csv file from your Google Street View downloads\n",
        "pano_df = pd.read_csv(data_file, index_col = 0, header=0)\n",
        "pano_df.head()\n",
        "pano_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = project.version(\"3\").model"
      ],
      "metadata": {
        "id": "hsX7WMJePYl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print sample detections for the first 100 images\n",
        "import json\n",
        "for i in range(100):\n",
        "    panoid = pano_df.iloc[i]['panoID']\n",
        "    lat = pano_df.iloc[i]['lat']\n",
        "    lon = pano_df.iloc[i]['lon']\n",
        "    print(i,'processing panoID:', panoid)\n",
        "\n",
        "    for heading in [0,90,180,270]:\n",
        "        filename = panoid+\"_\"+str(heading)+\".jpg\"\n",
        "        img_path = image_directory + filename\n",
        "        try:\n",
        "            prediction = model.predict(img_path, confidence=80, overlap=30)\n",
        "            prediction.plot()\n",
        "        except Exception as ex:\n",
        "            print('Error', ex)"
      ],
      "metadata": {
        "id": "Jbalridy_-32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cldJ9pX82xpt",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "#Deploy object detection model on the entire GSV image dataset\n",
        "\n",
        "detections = []\n",
        "for i in range(len(pano_df)):\n",
        "    panoid = pano_df.iloc[i]['panoID']\n",
        "    lat = pano_df.iloc[i]['lat']\n",
        "    lon = pano_df.iloc[i]['lon']\n",
        "    print(i,'processing panoID:', panoid)\n",
        "\n",
        "    for heading in [0,90,180,270]:\n",
        "        filename = panoid+\"_\"+str(heading)+\".jpg\"\n",
        "        img_path = image_directory + filename\n",
        "        try:\n",
        "            prediction = model.predict(img_path, confidence=80, overlap=30) # Establishing a minimum confidence threshold of 80 percent. Change as needed.\n",
        "            prediction_json = json.dumps(prediction.json())\n",
        "            classes = json.loads(prediction_json)['predictions'][0]['class']\n",
        "            confidence = json.loads(prediction_json)['predictions'][0]['confidence']\n",
        "            detections.append([panoid, lat, lon, filename, classes, confidence])\n",
        "            print(\"Detection added for image:\", filename)\n",
        "        except Exception as ex:\n",
        "            print('Error', ex)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile a dictionary of the detections including panoID, latitute, longitude, filename, classes, and confidence level\n",
        "\n",
        "detection_dicts = [{'panoID':detection[0],'lat':detection[1],'lon':detection[2],'filename':detection[3],'classes':detection[4],'confidence':detection[5]} for detection in detections]\n",
        "print(\"Detection dict created:\", detection_dicts)\n",
        "with open(savename, \"w\") as json_file:\n",
        "    json.dump(detection_dicts, json_file)\n",
        "\n",
        "detection_dicts"
      ],
      "metadata": {
        "id": "bB_4XGMmOBQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bK3V2yygARN5"
      },
      "source": [
        "VISUALIZE DETECTIONS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PiOgEfC2xpt"
      },
      "outputs": [],
      "source": [
        "# Load the detections from a json file into a pandas dataframe\n",
        "detections_df = pd.read_json(savename)\n",
        "\n",
        "# Replace \"filepath\" below as appropriate to establish where to save the detections in a .csv file format\n",
        "detections_df.to_csv(\"filepath/detections.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Establish visual features of the map of the detected public water points\n",
        "zoom_level = 15\n",
        "center = [pano_df['lat'].mean(), pano_df['lon'].mean()]\n",
        "theme = 'CartoDB positron'\n",
        "color = 'green'"
      ],
      "metadata": {
        "id": "CqGI1GeULVUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Map the newly-detected public water point sites\n",
        "map1 = folium.Map(location=center,tiles=theme,zoom_start=15)\n",
        "\n",
        "for index, row in detections_df.iterrows():\n",
        "    folium.CircleMarker([row['lat'], row['lon']],radius=.01,fill=True, color=color,opacity=1, fill_color=color,fill_opacity=1).add_to(map1)\n",
        "\n",
        "map1"
      ],
      "metadata": {
        "id": "aDRHA7JjcEpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kqqsdsYbG3F"
      },
      "source": [
        "MANUAL VALIDATION OF MODEL PERFORMANCE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the 'detections.csv' file listed above, replacing \"filepath\" below as appropriate\n",
        "manval_df = pd.read_csv(\"filepath to detections.csv\", index_col = 0, header=0)\n",
        "manval_df.head()"
      ],
      "metadata": {
        "id": "HPfcOZHNOMsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out all detections to manually validate for false positives or false negatives\n",
        "for i in range(100):\n",
        "    panoid = manval_df.iloc[i]['panoID']\n",
        "    lat = manval_df.iloc[i]['lat']\n",
        "    lon = manval_df.iloc[i]['lon']\n",
        "    print(i,'processing panoID:', panoid)\n",
        "\n",
        "    for heading in [0,90,180,270]:\n",
        "        filename = panoid+\"_\"+str(heading)+\".jpg\"\n",
        "        img_path = image_directory + filename\n",
        "        try:\n",
        "            prediction = model.predict(img_path, confidence=80, overlap=30)\n",
        "            prediction.plot()\n",
        "        except Exception as ex:\n",
        "            print('Error', ex)"
      ],
      "metadata": {
        "id": "ABg2UCVrOqfd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
